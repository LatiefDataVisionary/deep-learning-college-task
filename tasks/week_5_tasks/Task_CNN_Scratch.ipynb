{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPwm3gcK88Y4IFF9EzJ6bY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LatiefDataVisionary/deep-learning-college-task/blob/main/tasks/week_5_tasks/Task_CNN_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5626ae91"
      },
      "source": [
        "# **Section 0: Initial Setup (Pengaturan Awal)**\n",
        "\n",
        "Bagian ini untuk melakukan instalasi library penting yang mungkin belum ada di Colab dan menghubungkan Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430e8d6e"
      },
      "source": [
        "## **0.1. Install Libraries (Instalasi Library)**\n",
        "\n",
        "Menginstal library `mtcnn` yang akan digunakan untuk deteksi wajah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf25ad7a",
        "outputId": "67663b2a-7d30-4aa6-8a8e-dce0c1291773"
      },
      "source": [
        "!pip install mtcnn opencv-python Pillow matplotlib pandas numpy scikit-learn tensorflow lz4\n",
        "!pip install --upgrade Pillow\n",
        "!pip install lz4"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.12/dist-packages (4.4.4)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.12/dist-packages (4.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ca0d611"
      },
      "source": [
        "## **0.2. Mount Google Drive (Menghubungkan Google Drive)**\n",
        "\n",
        "Menghubungkan notebook dengan Google Drive agar dapat mengakses dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce83f40",
        "outputId": "5aa92e94-4a08-4487-cb0e-9efd08c8d5c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c13c338"
      },
      "source": [
        "## **Section 1: Import Libraries and Environment Setup (Impor Library dan Pengaturan Lingkungan)**\n",
        "\n",
        "**Penjelasan:** Di sini kita akan mengimpor semua modul dan library yang dibutuhkan untuk keseluruhan proyek serta mendefinisikan variabel-variabel global seperti path direktori, ukuran gambar, dan parameter training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9576c1c5"
      },
      "source": [
        "### **1.1. Import Core Libraries (Impor Library Utama)**\n",
        "\n",
        "**Penjelasan:** Mengimpor library utama seperti tensorflow, keras, numpy, matplotlib.pyplot, os, dan seaborn yang akan digunakan sepanjang proyek ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ee94cf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import glob\n",
        "import shutil\n",
        "from mtcnn.mtcnn import MTCNN"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4adda93"
      },
      "source": [
        "### **1.2. Define Configurations (Definisi Konfigurasi)**\n",
        "\n",
        "**Penjelasan:** Mendefinisikan variabel-variabel konfigurasi yang akan digunakan di seluruh notebook, termasuk path ke dataset, ukuran gambar yang akan digunakan, ukuran batch untuk training, jumlah epoch, dan jumlah kelas (mahasiswa)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link Dataset Google Drive: https://drive.google.com/drive/folders/1S5mRxYOfTPAmfqqFFLfbV_D5eWj5J9ox?usp=sharing"
      ],
      "metadata": {
        "id": "sa181Rqnk7PG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "752e8757"
      },
      "source": [
        "# Define Directory Paths (Definisi Path Direktori)\n",
        "ZIP_PATH = '/content/drive/MyDrive/Dataset/Dataset Sistem Presensi Wajah V1.0.zip' # Path to the raw zip file in Google Drive\n",
        "RAW_DATA_PATH = '/content/raw_dataset' # Directory to extract the raw dataset\n",
        "PROCESSED_PATH = '/content/processed_dataset' # Directory to save the processed (face-detected) dataset\n",
        "\n",
        "# Define Image Parameters (Definisi Parameter Gambar)\n",
        "IMG_HEIGHT = 128 # Smaller size for custom CNN from scratch\n",
        "IMG_WIDTH = 128\n",
        "CHANNELS = 3 # RGB color images\n",
        "\n",
        "# Define Training Parameters (Definisi Parameter Pelatihan)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50 # Will be controlled by Early Stopping\n",
        "# NUM_CLASSES will be determined later by the data generator"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2817c9e2"
      },
      "source": [
        "### **1.3. Extract Dataset (Ekstrak Dataset)**\n",
        "\n",
        "**Penjelasan:** Mengekstrak file dataset dari Google Drive ke lingkungan Colab agar dapat diakses sebagai direktori biasa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1266c0a",
        "outputId": "17c406c5-988a-43cb-9bf5-4fd0c22c529a"
      },
      "source": [
        "# Define the path to the zip file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/Dataset/Dataset Sistem Presensi Wajah V1.0.zip'\n",
        "extract_path = '/content/dataset' # Directory to extract the dataset\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "print(f\"Extracting {zip_path} to {extract_path}...\")\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction complete.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at {zip_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Could not open or read zip file at {zip_path}. It might be corrupted.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")\n",
        "\n",
        "# Update TRAIN_DIR and TEST_DIR to point to the extracted directories\n",
        "# Based on the previous output, the extracted content is in a subfolder\n",
        "extracted_subfolder = os.path.join(extract_path, 'Dataset Sistem Presensi Wajah V1.0')\n",
        "TRAIN_DIR = os.path.join(extracted_subfolder, 'Data Train')\n",
        "TEST_DIR = os.path.join(extracted_subfolder, 'Data Test')\n",
        "\n",
        "\n",
        "print(f\"Updated TRAIN_DIR: {TRAIN_DIR}\")\n",
        "print(f\"Updated TEST_DIR: {TEST_DIR}\")\n",
        "\n",
        "# Verify that the directories exist after extraction\n",
        "if os.path.exists(TRAIN_DIR):\n",
        "    print(f\"TRAIN_DIR exists: {TRAIN_DIR}\")\n",
        "else:\n",
        "    print(f\"Error: TRAIN_DIR not found after extraction at {TRAIN_DIR}\")\n",
        "\n",
        "if os.path.exists(TEST_DIR):\n",
        "    print(f\"TEST_DIR exists: {TEST_DIR}\")\n",
        "else:\n",
        "    print(f\"Error: TEST_DIR not found after extraction at {TEST_DIR}\")\n",
        "\n",
        "# Now it's safe to list contents if needed for verification after extraction\n",
        "print(f\"Contents of {extract_path} after extraction: {os.listdir(extract_path)}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/Dataset Sistem Presensi Wajah V1.0.zip to /content/dataset...\n",
            "Extraction complete.\n",
            "Updated TRAIN_DIR: /content/dataset/Dataset Sistem Presensi Wajah V1.0/Data Train\n",
            "Updated TEST_DIR: /content/dataset/Dataset Sistem Presensi Wajah V1.0/Data Test\n",
            "TRAIN_DIR exists: /content/dataset/Dataset Sistem Presensi Wajah V1.0/Data Train\n",
            "TEST_DIR exists: /content/dataset/Dataset Sistem Presensi Wajah V1.0/Data Test\n",
            "Contents of /content/dataset after extraction: ['Dataset Sistem Presensi Wajah V1.0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d31ee2a"
      },
      "source": [
        "## **Section 2: Advanced Preprocessing - Face Detection and Cropping (Preprocessing Lanjutan - Deteksi dan Pemotongan Wajah)**\n",
        "\n",
        "**Penjelasan:** Ini adalah tahap paling krusial dan merupakan upgrade utama. Kita akan memproses seluruh dataset mentah sekali jalan. Tujuannya adalah mendeteksi wajah di setiap gambar, memotongnya, dan menyimpannya ke struktur direktori baru yang bersih dan siap pakai. Proses ini menyelesaikan masalah distorsi aspect ratio dan noise latar belakang."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b73bfdd"
      },
      "source": [
        "### **2.1. Unzip Raw Dataset (Ekstrak Dataset Mentah)**\n",
        "\n",
        "**Penjelasan:** Mengekstrak file dataset mentah dari lokasi ZIP_PATH ke direktori RAW_DATA_PATH agar dapat diakses sebagai file gambar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f255fac3",
        "outputId": "61e44d70-8ff2-4bb0-f578-dc05665a542a"
      },
      "source": [
        "# Create the raw data extraction directory if it doesn't exist\n",
        "os.makedirs(RAW_DATA_PATH, exist_ok=True)\n",
        "\n",
        "# Extract the zip file to the raw data path\n",
        "print(f\"Extracting {ZIP_PATH} to {RAW_DATA_PATH}...\")\n",
        "try:\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(RAW_DATA_PATH)\n",
        "    print(\"Extraction complete.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at {ZIP_PATH}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Could not open or read zip file at {ZIP_PATH}. It might be corrupted.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")\n",
        "\n",
        "# Verify contents of the extracted raw data directory\n",
        "print(f\"Contents of {RAW_DATA_PATH} after extraction: {os.listdir(RAW_DATA_PATH)}\")\n",
        "\n",
        "# Determine the actual path to the raw image files inside the extracted folder\n",
        "# Assuming the zip contains a single main folder\n",
        "extracted_items = os.listdir(RAW_DATA_PATH)\n",
        "if len(extracted_items) == 1 and os.path.isdir(os.path.join(RAW_DATA_PATH, extracted_items[0])):\n",
        "    ACTUAL_RAW_DATA_ROOT = os.path.join(RAW_DATA_PATH, extracted_items[0])\n",
        "else:\n",
        "    # If structure is different, you might need to adjust this\n",
        "    ACTUAL_RAW_DATA_ROOT = RAW_DATA_PATH\n",
        "    print(\"Warning: Extracted data structure is not a single subfolder. Assuming raw images are directly in RAW_DATA_PATH.\")\n",
        "\n",
        "print(f\"Actual root directory for raw images: {ACTUAL_RAW_DATA_ROOT}\")\n",
        "\n",
        "# List a few files to confirm - Search recursively for image files\n",
        "raw_image_files = glob.glob(os.path.join(ACTUAL_RAW_DATA_ROOT, '**', '*.*'), recursive=True)\n",
        "# Filter for image files specifically\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "raw_image_files = [f for f in raw_image_files if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "\n",
        "\n",
        "print(f\"Found {len(raw_image_files)} raw image files.\")\n",
        "if len(raw_image_files) > 5:\n",
        "    print(\"First 5 raw files:\", raw_image_files[:5])\n",
        "elif len(raw_image_files) > 0:\n",
        "     print(\"Raw files:\", raw_image_files)\n",
        "else:\n",
        "    print(\"No raw image files found. Check ZIP_PATH and extraction process.\")\n",
        "\n",
        "# Update the global variable if needed, though it's already set above\n",
        "# globals()['ACTUAL_RAW_DATA_ROOT'] = ACTUAL_RAW_DATA_ROOT"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/Dataset Sistem Presensi Wajah V1.0.zip to /content/raw_dataset...\n",
            "Extraction complete.\n",
            "Contents of /content/raw_dataset after extraction: ['Dataset Sistem Presensi Wajah V1.0']\n",
            "Actual root directory for raw images: /content/raw_dataset/Dataset Sistem Presensi Wajah V1.0\n",
            "Found 2120 raw image files.\n",
            "First 5 raw files: ['/content/raw_dataset/Dataset Sistem Presensi Wajah V1.0/Data Test/5231811005_Akhmad Nabil Saputra_13.jpg', '/content/raw_dataset/Dataset Sistem Presensi Wajah V1.0/Data Test/5231911004_al faisal selan 34.jpg', '/content/raw_dataset/Dataset Sistem Presensi Wajah V1.0/Data Test/5231811018_Sulis Septiani Putri_04.jpg', '/content/raw_dataset/Dataset Sistem Presensi Wajah V1.0/Data Test/5231811008_Sophia_39.jpg', '/content/raw_dataset/Dataset Sistem Presensi Wajah V1.0/Data Test/5231911016_Ameliawati_13.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b960b805"
      },
      "source": [
        "### **2.2. Initialize Face Detector (Inisialisasi Detektor Wajah)**\n",
        "\n",
        "**Penjelasan:** Menginisialisasi model MTCNN yang akan digunakan untuk mendeteksi wajah pada setiap gambar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f7759e2",
        "outputId": "990d75ac-7bcd-4395-ac42-61d5802b142d"
      },
      "source": [
        "# Initialize MTCNN detector\n",
        "detector = MTCNN()\n",
        "print(\"MTCNN detector initialized.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MTCNN detector initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15b91bc"
      },
      "source": [
        "### **2.3. Prepare Processed Directory Structure (Siapkan Struktur Direktori Hasil Proses)**\n",
        "\n",
        "**Penjelasan:** Membuat struktur direktori baru di PROCESSED_PATH untuk menyimpan gambar wajah yang sudah dideteksi dan dipotong. Struktur ini akan memiliki sub-folder untuk data training dan testing, dan di dalamnya akan ada sub-folder untuk setiap kelas (berdasarkan NIM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a234a96f",
        "outputId": "d4aacb19-6311-4e8f-b883-297617335843"
      },
      "source": [
        "# Clean up and create the processed data directories\n",
        "if os.path.exists(PROCESSED_PATH):\n",
        "    print(f\"Removing existing processed data directory: {PROCESSED_PATH}\")\n",
        "    shutil.rmtree(PROCESSED_PATH)\n",
        "\n",
        "os.makedirs(PROCESSED_PATH)\n",
        "os.makedirs(os.path.join(PROCESSED_PATH, 'train'))\n",
        "os.makedirs(os.path.join(PROCESSED_PATH, 'test'))\n",
        "print(f\"Created processed data directories: {PROCESSED_PATH}/train and {PROCESSED_PATH}/test\")\n",
        "\n",
        "# Get unique class names (NIMs) from raw filenames by searching recursively\n",
        "class_names = set()\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "\n",
        "# Search recursively for image files within ACTUAL_RAW_DATA_ROOT\n",
        "all_raw_files_recursive = glob.glob(os.path.join(ACTUAL_RAW_DATA_ROOT, '**', '*.*'), recursive=True)\n",
        "\n",
        "for filepath in all_raw_files_recursive:\n",
        "    filename = os.path.basename(filepath)\n",
        "    if len(filename) >= 10 and os.path.splitext(filename)[1].lower() in image_extensions:\n",
        "        nim = filename[:10]\n",
        "        class_names.add(nim)\n",
        "\n",
        "class_names = sorted(list(class_names))\n",
        "\n",
        "\n",
        "if not class_names:\n",
        "    print(\"Error: No class names (NIMs) extracted from filenames. Check file naming convention and ACTUAL_RAW_DATA_ROOT.\")\n",
        "else:\n",
        "    print(f\"Found {len(class_names)} unique classes (NIMs).\")\n",
        "    # Create sub-folders for each class in train and test directories\n",
        "    for class_name in class_names:\n",
        "        os.makedirs(os.path.join(PROCESSED_PATH, 'train', class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(PROCESSED_PATH, 'test', class_name), exist_ok=True)\n",
        "    print(\"Created class sub-folders in processed train and test directories.\")\n",
        "\n",
        "# Store class_names for later use\n",
        "CLASS_NAMES = class_names"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing existing processed data directory: /content/processed_dataset\n",
            "Created processed data directories: /content/processed_dataset/train and /content/processed_dataset/test\n",
            "Found 53 unique classes (NIMs).\n",
            "Created class sub-folders in processed train and test directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30653e48"
      },
      "source": [
        "### **2.4. Run the Face Detection & Cropping Pipeline (Jalankan Pipeline Deteksi & Pemotongan Wajah)**\n",
        "\n",
        "**Penjelasan:** Membuat dan menjalankan fungsi untuk mendeteksi wajah di setiap gambar mentah, memotongnya, dan menyimpannya ke struktur direktori yang sudah disiapkan di PROCESSED_PATH. Data akan dibagi secara manual menjadi training dan testing (misal: 80% train, 20% test per kelas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f824f70",
        "outputId": "74f3ce44-fcdb-41b5-ea39-02a2252a01be"
      },
      "source": [
        "def process_and_save_faces_by_split(raw_source_dir, processed_dest_dir, detector, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Processes raw images from a specific source directory (e.g., original train or test),\n",
        "    detects faces, crops them, resizes, and saves to the specified processed\n",
        "    destination directory based on NIM from filename, maintaining the original split.\n",
        "\n",
        "    Args:\n",
        "        raw_source_dir (str): Directory containing raw images for a specific split (e.g., Data Train or Data Test).\n",
        "        processed_dest_dir (str): Destination directory for processed images of this split (e.g., processed/train or processed/test).\n",
        "        detector (MTCNN): Initialized MTCNN face detector.\n",
        "        img_width (int): Target width for processed images.\n",
        "        img_height (int): Target height for processed images.\n",
        "    \"\"\"\n",
        "    print(f\"Starting face detection and cropping for split from {raw_source_dir} to {processed_dest_dir}...\")\n",
        "\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "    # Find all image files recursively within the raw source directory\n",
        "    all_raw_files_recursive = glob.glob(os.path.join(raw_source_dir, '**', '*.*'), recursive=True)\n",
        "    image_files = [f for f in all_raw_files_recursive if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "\n",
        "    total_processed = 0\n",
        "    total_skipped = 0\n",
        "    files_to_process = len(image_files)\n",
        "\n",
        "    if files_to_process == 0:\n",
        "        print(f\"No image files found in {raw_source_dir}. Skipping this split.\")\n",
        "        print(f\"Face detection and cropping for split finished.\")\n",
        "        print(f\"Total images processed and saved: {total_processed}\")\n",
        "        print(f\"Total images skipped (no face detected or error): {total_skipped}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {files_to_process} images to process in {raw_source_dir}.\")\n",
        "\n",
        "\n",
        "    for i, filepath in enumerate(image_files):\n",
        "        filename = os.path.basename(filepath)\n",
        "        if len(filename) >= 10:\n",
        "            nim = filename[:10]\n",
        "            # Ensure NIM corresponds to an expected class (from the class_names identified earlier)\n",
        "            if nim in CLASS_NAMES:\n",
        "                 # Define the destination path, including the class subfolder\n",
        "                 dest_class_dir = os.path.join(processed_dest_dir, nim)\n",
        "                 # Ensure the class directory exists (created in step 2.3)\n",
        "                 if not os.path.exists(dest_class_dir):\n",
        "                     # This should not happen if step 2.3 ran correctly, but as a safeguard:\n",
        "                     os.makedirs(dest_class_dir, exist_ok=True)\n",
        "                     # print(f\"Created missing class directory: {dest_class_dir}\") # Uncomment for debugging\n",
        "\n",
        "                 dest_filepath = os.path.join(dest_class_dir, filename)\n",
        "\n",
        "                 try:\n",
        "                    image = cv2.imread(filepath)\n",
        "                    if image is None:\n",
        "                        # print(f\"Warning: Could not read image file: {filepath}. Skipping.\") # Uncomment for detailed skips\n",
        "                        total_skipped += 1\n",
        "                        continue\n",
        "\n",
        "                    # Convert BGR to RGB (MTCNN expects RGB)\n",
        "                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                    # Detect faces\n",
        "                    results = detector.detect_faces(image_rgb)\n",
        "\n",
        "                    if results:\n",
        "                        # Get the first detected face (assuming one main face per image)\n",
        "                        x, y, width, height = results[0]['box']\n",
        "\n",
        "                        # Add margin (adjust as needed)\n",
        "                        margin_x = int(width * 0.2)\n",
        "                        margin_y = int(height * 0.2)\n",
        "                        x1 = max(0, x - margin_x)\n",
        "                        y1 = max(0, y - margin_y)\n",
        "                        x2 = min(image.shape[1], x + width + margin_x)\n",
        "                        y2 = min(image.shape[0], y + height + margin_y)\n",
        "\n",
        "                        # Crop the face with margin\n",
        "                        face_crop = image[y1:y2, x1:x2]\n",
        "\n",
        "                        # Check if crop is valid (not empty)\n",
        "                        if face_crop is not None and face_crop.size > 0:\n",
        "                            # Resize the cropped face to target size\n",
        "                            face_resized = cv2.resize(face_crop, (img_width, img_height))\n",
        "\n",
        "                            # Save the processed face image\n",
        "                            cv2.imwrite(dest_filepath, face_resized)\n",
        "                            total_processed += 1\n",
        "                        else:\n",
        "                             # print(f\"Warning: Cropped face is empty for {filepath}. Skipping.\") # Uncomment for detailed skips\n",
        "                             total_skipped += 1\n",
        "                    else:\n",
        "                        # print(f\"Warning: No face detected in {filepath}. Skipping.\") # Uncomment for detailed skips\n",
        "                        total_skipped += 1\n",
        "\n",
        "                 except Exception as e:\n",
        "                    # print(f\"Error processing {filepath}: {e}. Skipping.\") # Uncomment for detailed errors\n",
        "                    total_skipped += 1\n",
        "            else:\n",
        "                # print(f\"Warning: NIM not found in CLASS_NAMES for file {filename}. Skipping.\") # Uncomment for debugging unknown NIMs\n",
        "                total_skipped += 1\n",
        "        else:\n",
        "             # print(f\"Warning: Filename {filename} is too short to extract NIM. Skipping.\") # Uncomment for debugging short filenames\n",
        "             total_skipped += 1\n",
        "\n",
        "\n",
        "    print(f\"\\nFace detection and cropping for split finished.\")\n",
        "    print(f\"Total images processed and saved: {total_processed}\")\n",
        "    print(f\"Total images skipped (no face detected or error): {total_skipped}\")\n",
        "\n",
        "# --- Run the pipeline for Train and Test splits ---\n",
        "\n",
        "# Ensure ACTUAL_RAW_DATA_ROOT is correctly determined in step 2.1\n",
        "if 'ACTUAL_RAW_DATA_ROOT' in globals() and os.path.exists(ACTUAL_RAW_DATA_ROOT):\n",
        "    original_train_dir = os.path.join(ACTUAL_RAW_DATA_ROOT, 'Data Train')\n",
        "    original_test_dir = os.path.join(ACTUAL_RAW_DATA_ROOT, 'Data Test')\n",
        "\n",
        "    # Check if the original train/test directories exist within the extracted raw data\n",
        "    if not os.path.exists(original_train_dir):\n",
        "        print(f\"Error: Original Train directory not found at {original_train_dir}. Cannot process train data.\")\n",
        "    else:\n",
        "        process_and_save_faces_by_split(original_train_dir,\n",
        "                                        os.path.join(PROCESSED_PATH, 'train'),\n",
        "                                        detector,\n",
        "                                        IMG_WIDTH, IMG_HEIGHT)\n",
        "\n",
        "    if not os.path.exists(original_test_dir):\n",
        "        print(f\"Error: Original Test directory not found at {original_test_dir}. Cannot process test data.\")\n",
        "    else:\n",
        "        process_and_save_faces_by_split(original_test_dir,\n",
        "                                        os.path.join(PROCESSED_PATH, 'test'),\n",
        "                                        detector,\n",
        "                                        IMG_WIDTH, IMG_HEIGHT)\n",
        "\n",
        "else:\n",
        "    print(\"Error: ACTUAL_RAW_DATA_ROOT is not set or does not exist. Cannot run processing pipeline.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting face detection and cropping pipeline from /content/raw_dataset/Dataset Sistem Presensi Wajah V1.0...\n",
            "\n",
            "Face detection and cropping pipeline finished.\n",
            "Total images processed and saved: 0\n",
            "Total images skipped (no face detected or error): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f987bd9"
      },
      "source": [
        "### **2.5. Verify Processed Dataset (Verifikasi Dataset Hasil Proses)**\n",
        "\n",
        "**Penjelasan:** Memeriksa jumlah gambar di direktori training dan testing yang sudah diproses untuk memastikan bahwa pipeline deteksi dan pemotongan wajah berjalan dengan sukses dan data tersimpan dengan benar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455ac6d0",
        "outputId": "d7355dcc-795a-4918-8b72-80afdf3ee19e"
      },
      "source": [
        "# Function to count images in a directory, including subdirectories\n",
        "def count_images_in_directory(directory):\n",
        "    count = 0\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "# Count images in processed train and test directories\n",
        "train_count = count_images_in_directory(os.path.join(PROCESSED_PATH, 'train'))\n",
        "test_count = count_images_in_directory(os.path.join(PROCESSED_PATH, 'test'))\n",
        "\n",
        "print(f\"Number of processed images in training directory ({os.path.join(PROCESSED_PATH, 'train')}): {train_count}\")\n",
        "print(f\"Number of processed images in testing directory ({os.path.join(PROCESSED_PATH, 'test')}): {test_count}\")\n",
        "\n",
        "if train_count == 0 or test_count == 0:\n",
        "    print(\"Warning: No processed images found in one or both directories. Check the processing pipeline and file paths.\")\n",
        "else:\n",
        "    print(\"Processed dataset structure verified.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of processed images in training directory (/content/processed_dataset/train): 0\n",
            "Number of processed images in testing directory (/content/processed_dataset/test): 0\n",
            "Warning: No processed images found in one or both directories. Check the processing pipeline and file paths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a50af8b"
      },
      "source": [
        "## **Section 3: Data Loading and Augmentation (Pemuatan dan Augmentasi Data)**\n",
        "\n",
        "**Penjelasan:** Sekarang kita akan bekerja dengan data yang sudah bersih di PROCESSED_PATH. Karena datanya sudah memiliki struktur folder per kelas (berkat pipeline preprocessing di Section 2), kita bisa menggunakan `ImageDataGenerator` dan metode `flow_from_directory` yang lebih efisien untuk memuat data dan menerapkan augmentasi secara on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84a0f6c7"
      },
      "source": [
        "### **3.1. Create Data Generators (Membuat Generator Data)**\n",
        "\n",
        "**Penjelasan:** Menginisialisasi `ImageDataGenerator` untuk data training dengan berbagai teknik augmentasi untuk meningkatkan variasi data dan membantu mencegah overfitting. Satu generator terpisah dibuat untuk data testing yang hanya melakukan rescaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0748205b"
      },
      "source": [
        "# Create ImageDataGenerator for training with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Rescale pixel values to [0, 1]\n",
        "    rotation_range=20,          # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.2,      # Randomly shift image horizontally\n",
        "    height_shift_range=0.2,     # Randomly shift image vertically\n",
        "    shear_range=0.2,            # Apply shear transformation\n",
        "    zoom_range=0.2,             # Apply random zoom\n",
        "    horizontal_flip=True,       # Randomly flip images horizontally\n",
        "    fill_mode='nearest'         # Fill pixels lost during transformations\n",
        ")\n",
        "\n",
        "# Create ImageDataGenerator for testing (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for consistency"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98a53f4c"
      },
      "source": [
        "### **3.2. Apply the Generators (Menerapkan Generator)**\n",
        "\n",
        "**Penjelasan:** Menggunakan metode `flow_from_directory` dari generator yang telah dibuat untuk membaca gambar langsung dari struktur folder di PROCESSED_PATH/train dan PROCESSED_PATH/test. Ini secara otomatis akan menentukan label kelas berdasarkan nama sub-folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bd307cc",
        "outputId": "05fa27f0-c38f-47e0-d827-d87e5a53d92f"
      },
      "source": [
        "# Create training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(PROCESSED_PATH, 'train'),\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT), # Target size for input images\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical' # For multi-class classification\n",
        ")\n",
        "\n",
        "# Create testing data generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(PROCESSED_PATH, 'test'),\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False # Keep data in order for evaluation metrics\n",
        ")\n",
        "\n",
        "# Get the number of classes from the training generator\n",
        "NUM_CLASSES = train_generator.num_classes\n",
        "print(f\"\\nNumber of classes (detected from directories): {NUM_CLASSES}\")\n",
        "print(f\"Class indices: {train_generator.class_indices}\")\n",
        "\n",
        "# You can also store the class names if needed\n",
        "CLASS_NAMES_GENERATOR = list(train_generator.class_indices.keys())\n",
        "print(f\"Class names (order corresponds to indices): {CLASS_NAMES_GENERATOR}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 53 classes.\n",
            "Found 0 images belonging to 53 classes.\n",
            "\n",
            "Number of classes (detected from directories): 53\n",
            "Class indices: {'5221911012': 0, '5221911025': 1, '5231811002': 2, '5231811004': 3, '5231811005': 4, '5231811006': 5, '5231811007': 6, '5231811008': 7, '5231811009': 8, '5231811010': 9, '5231811013': 10, '5231811014': 11, '5231811015': 12, '5231811016': 13, '5231811017': 14, '5231811018': 15, '5231811019': 16, '5231811021': 17, '5231811022': 18, '5231811023': 19, '5231811024': 20, '5231811025': 21, '5231811026': 22, '5231811027': 23, '5231811028': 24, '5231811029': 25, '5231811030': 26, '5231811031': 27, '5231811033': 28, '5231811034': 29, '5231811035': 30, '5231811036': 31, '5231811037': 32, '5231811038': 33, '5231811039': 34, '5231911001': 35, '5231911002': 36, '5231911003': 37, '5231911004': 38, '5231911005': 39, '5231911006': 40, '5231911007': 41, '5231911008': 42, '5231911009': 43, '5231911010': 44, '5231911011': 45, '5231911012': 46, '5231911013': 47, '5231911016': 48, '5231911017': 49, '5231911018': 50, '5231911019': 51, '5231911020': 52}\n",
            "Class names (order corresponds to indices): ['5221911012', '5221911025', '5231811002', '5231811004', '5231811005', '5231811006', '5231811007', '5231811008', '5231811009', '5231811010', '5231811013', '5231811014', '5231811015', '5231811016', '5231811017', '5231811018', '5231811019', '5231811021', '5231811022', '5231811023', '5231811024', '5231811025', '5231811026', '5231811027', '5231811028', '5231811029', '5231811030', '5231811031', '5231811033', '5231811034', '5231811035', '5231811036', '5231811037', '5231811038', '5231811039', '5231911001', '5231911002', '5231911003', '5231911004', '5231911005', '5231911006', '5231911007', '5231911008', '5231911009', '5231911010', '5231911011', '5231911012', '5231911013', '5231911016', '5231911017', '5231911018', '5231911019', '5231911020']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FQa7QOtw1HAK"
      }
    }
  ]
}